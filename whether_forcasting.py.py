# -*- coding: utf-8 -*-
"""whether_forcasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19xmuHG6N91hpEjsE7ZSffngxbbuUjSi2
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from google.colab import files

# --- 1. Data Loading ---
print("Please upload the 'seattle-weather.csv' file from Kaggle when prompted.")
try:
    # This will open the file selection dialog in Colab
    uploaded = files.upload()
    file_name = "seattle-weather.csv"
    if file_name in uploaded:
        df = pd.read_csv(file_name)
    else:
        # Fallback if user renames the file or it's already in the session
        df = pd.read_csv(next(iter(uploaded)))
except Exception as e:
    print(f"An error occurred during file upload or reading: {e}")
    print("Please ensure the file 'seattle-weather.csv' is uploaded correctly.")
    # Exit if loading fails
    exit()

# --- 2. Initial Data Inspection and Cleaning ---
print("\n--- Dataset Head ---")
print(df.head().to_markdown(index=False))

print("\n--- Missing Values Check ---")
print(df.isnull().sum()) # Check for missing values

# There are no missing values in this dataset, but if there were, we'd handle them here.

# --- 3. Feature Engineering and Preprocessing ---

# Convert the 'date' column to datetime objects
df['date'] = pd.to_datetime(df['date'])

# Extract useful time-based features
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['year'] = df['date'].dt.year

# Create a 'Weather' lag feature: The weather condition of the previous day often predicts today's.
# We'll use a lag of 1 day for the target variable itself.
# Sort by date and apply the shift.
df = df.sort_values(by='date').reset_index(drop=True)
df['prev_day_weather'] = df['weather'].shift(1)

# Drop the first row which will have a NaN for 'prev_day_weather' and the original date column
df = df.dropna(subset=['prev_day_weather']).drop('date', axis=1)

# The target variable 'weather' is categorical, so we need to encode it for the model.
le = LabelEncoder()
df['weather_encoded'] = le.fit_transform(df['weather'])

# Prepare categorical features for the model using one-hot encoding
df = pd.get_dummies(df, columns=['prev_day_weather'], drop_first=True)

# --- 4. Exploratory Data Analysis (EDA) ---

# Plot the distribution of the target variable
plt.figure(figsize=(8, 5))
sns.countplot(y='weather', data=df, order=df['weather'].value_counts().index, palette='Spectral')
plt.title('Distribution of Weather Conditions')
plt.xlabel('Count')
plt.ylabel('Weather Type')
plt.tight_layout()
plt.savefig('weather_distribution.png')
plt.show()


# --- 5. Model Setup ---

# Define features (X) and target (y)
# Drop the original 'weather' string column and other columns not needed for features
X = df.drop(['weather', 'weather_encoded'], axis=1)
y = df['weather_encoded']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


# --- 6. Model Training and Prediction ---

# Using Random Forest, a powerful and robust classification algorithm
model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')

print("\n--- Training Random Forest Classifier... ---")
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)


# --- 7. Model Evaluation ---

# Map encoded predictions back to original weather labels for clear interpretation
target_names = le.classes_
y_test_labels = le.inverse_transform(y_test)
y_pred_labels = le.inverse_transform(y_pred)

print("\n--- Model Evaluation (Random Forest) ---")
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}\n")

print("Classification Report:")
print(classification_report(y_test_labels, y_pred_labels, target_names=target_names))

# Plot Confusion Matrix
cm = confusion_matrix(y_test_labels, y_pred_labels, labels=target_names)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_names, yticklabels=target_names)
plt.title('Confusion Matrix for Weather Prediction')
plt.ylabel('Actual Weather')
plt.xlabel('Predicted Weather')
plt.tight_layout()
plt.savefig('confusion_matrix.png')
plt.show()

# --- 8. Feature Importance (Visualization) ---

# Get feature importance scores
feature_importances = pd.Series(model.feature_importances_, index=X.columns)

# Plot top 10 features
plt.figure(figsize=(10, 6))
feature_importances.nlargest(10).sort_values().plot(kind='barh', color='teal')
plt.title('Top 10 Feature Importances')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.tight_layout()
plt.savefig('feature_importance.png')
plt.show()

print("\n--- Project Completed ---")
print("Check the generated plots for data distribution, model performance (confusion matrix), and key predictors (feature importance).")